# NeurIPS 2023

| **Title** | **Paper** | **Code or Demo** | 
|:---------:|:---------:|:--------:|
| LLM-Pruner: On the Structural Pruning of Large Language Models | [![arXiv](https://img.shields.io/badge/arXiv-2305.11627-b31b1b.svg)](https://arxiv.org/abs/2305.11627) | [![GitHub](https://img.shields.io/github/stars/horseee/LLM-Pruner?style=social)](https://github.com/horseee/LLM-Pruner)|
| RADAR: Robust AI-Text Detection via Adversarial Learning | [![arXiv](https://img.shields.io/badge/arXiv-2307.03838-b31b1b.svg)](https://arxiv.org/abs/2307.03838) | [(Demo)](https://radar-app.vizhub.ai/)|
| Causal-structure Driven Augmentations for Text OOD Generalization | [![arXiv](https://img.shields.io/badge/arXiv-2310.12803-b31b1b.svg)](https://arxiv.org/abs/2310.12803) |
| Enhancing Large Language Models with Ensemble of
Critics for Mitigating Toxicity and Hallucination | [(OpenReview)](https://openreview.net/pdf?id=4uiOPSvbN6)|
| Do Language Models Know When They're Hallucinating References? | [![arXiv](https://img.shields.io/badge/arXiv-2305.18248-b31b1b.svg)](https://arxiv.org/abs/2305.18248) |
| "Diversity and Synthetic data" workshop talk by  Adji Bousson Dieng | | [![GitHub](https://img.shields.io/github/stars/vertaix/Vendi-Score?style=social)](https://github.com/vertaix/Vendi-Score) |
| When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and Limitations| [![arXiv](https://img.shields.io/badge/arXiv-2310.19698-b31b1b.svg)](https://arxiv.org/abs/2310.19698) |[![GitHub](https://img.shields.io/github/stars/AleksandarPetrov/prefix-tuning-theory?style=social)](https://github.com/AleksandarPetrov/prefix-tuning-theory) |
| D4: Improving LLM Pretraining via Document De-Duplication and Diversification | [![arXiv](https://img.shields.io/badge/arXiv-2308.12284-b31b1b.svg)](https://arxiv.org/abs/2308.12284) |
| Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias | [![arXiv](https://img.shields.io/badge/arXiv-2306.15895-b31b1b.svg)](https://arxiv.org/abs/2306.15895) |
| Good Data from Bad Models : Foundations of Threshold-based Auto-labeling | [![arXiv](https://img.shields.io/badge/arXiv-2211.12620-b31b1b.svg)](https://arxiv.org/abs/2211.12620) |
| Mitigating Source Bias for Fairer Weak Supervision | [![arXiv](https://img.shields.io/badge/arXiv-2303.17713-b31b1b.svg)](https://arxiv.org/abs/2303.17713)  |
| Geometry-Aware Adaptation for Pretrained Models | [![arXiv](https://img.shields.io/badge/arXiv-2307.12226-b31b1b.svg)](https://arxiv.org/abs/2307.12226) |
| Skill-it! A Data-Driven Skills Framework for Understanding and Training Language Models | [![arXiv](https://img.shields.io/badge/arXiv-2307.14430-b31b1b.svg)](https://arxiv.org/abs/2307.14430) |
| Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine | [![arXiv](https://img.shields.io/badge/arXiv-2311.16452-b31b1b.svg)](https://arxiv.org/abs/2311.16452) | [(Code)](https://github.com/microsoft/promptbase)|
| Textbooks Are All You Need: Phi2 | [![arXiv](https://img.shields.io/badge/arXiv-2309.05463-b31b1b.svg)](https://arxiv.org/abs/2309.05463) | [(Playground)](https://ai.azure.com/explore/models/microsoft-phi-2/version/4/registry/azureml-msr)|
| Chatbot to explore all of NeurIPS23 Microsft research (100+ papers) |  | [(Demo)](https://neurips-chatbot.azurewebsites.net/)|
| Chatbot to explore all of NeurIPS23 posters (1000+ posters) |  | [(Demo)](https://neurips-chatbot.azurewebsites.net/)|
| MISTRALâ€™S Mixtral-8x7B | [Mixtral of Experts](https://mistral.ai/news/mixtral-of-experts/) | [(Playground)](https://labs.perplexity.ai/)|
